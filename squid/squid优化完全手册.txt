
一、 概述 
squid是一款优秀的open source的代理服务器软件，可以运行于多种系统平台上，但是同其他商业化的产品相比，其缺点也是很明显的，那就是它的命中率和效率相对低下。 

本文主要讨论在不改变硬件条件之下，通过以下手段对squid进行性能优化： 

1． 编译一个高效的、精简的新内核； 
2． 对Cache分区采用reiserfs日志文件系统； 
3． 重新编译squid； 
4． 优化squid配置； 

对于优化的效果，我使用大名鼎鼎的cacheflow公司的测试工具――cfmc进行测试比较： 

首先用cfmc自带的一个脚本，从squid.conf的access.log中抽出RUL，然后以这些RUL为依据进行测试。 

服务器配置： 
型号：HP LH3 
CPU：PII450 
内存：256MB 100MHz ECC SDRAM DIMM 
硬盘：9.1GB Hot-Swap Ultra2 Hard Disk 
网卡：Ethernet Express PRO 100 10/100M X 2 
操作系统：RedHat 7.1 

优化前测试结果： 
Iteration 0: Cumulative statistics; 933 seconds elapsed 
Total objects: 72599, total object size: 513211102 bytes 
Average object size: 7069 bytes 
Average object response time: 2707 milliseconds 
Objects per second: 77.81 
Bytes per second: 550065, min: 550065, max: 879873 
URLs discarded due to socket or connection failures: 6955 
Redirections: 1017, Cookied objects: 1036 
Pragma no-cache objects: 1656, Non-200 HTTP response codes: 2505 

优化后测试结果： 
Iteration 0: Cumulative statistics; 688 seconds elapsed 
Total objects: 72599, total object size: 403833100 bytes 
Average object size: 5562 bytes 
Average object response time: 1890 milliseconds 
Objects per second: 105.52 
Bytes per second: 586966, min: 586966, max: 995582 
URLs discarded due to socket or connection failures: 16372 
Redirections: 1658, Cookied objects: 1000 
Pragma no-cache objects: 1454, Non-200 HTTP response codes: 3132 

通过对以上测试结果的比较，我们可以看出： 
优化后的Objects per second增加了35.6％，Average object response time减少了43.2％，对整体性能的提升还是比较明显的。 

二、 编译新内核 
我们采取这样的方式来编译内核：取消内核的模块支持，将服务器所有的硬件驱动编译到内核中，此外还要注意将对reiserfs文件系统的支持也编译到内核中，从而在提供系统性能的同时增加系统安全性。在2.4.10以上的版本中，已经内置了对reiserfs文件系统的支持。 

首先从http://www.kernel.org/pub/linux/kernel/v2.4/下载linux-2.4.12.tar.gz，这是当前最新的内核。 
然后解开内核文件： 
tar xvzf linux-2.4.12.tar.gz 
进入新生成的目录并执行： 
cd linux 
make mrproper 
make config 

根据我的服务器的配置，我选择这样编译内核： 

* Code maturity level options 
Prompt for development and/or incomplete code/drivers (CONFIG_EXPERIMENTAL) [Y/n/?] 
* Loadable module support 
Enable loadable module support (CONFIG_MODULES) [N/y/?] 
* Processor type and features 
Processor family (386, 486, 586/K5/5x86/6x86/6x86MX, Pentium-Classic, Pentium-MM 
X, Pentium-Pro/Celeron/Pentium-II, Pentium-III/Celeron(Coppermine), Pentium-4, K 
6/K6-II/K6-III, Athlon/Duron/K7, Crusoe, Winchip-C6, Winchip-2, Winchip-2A/Winch 
ip-3, CyrixIII/C3) [Pentium-Pro/Celeron/Pentium-II] 
* General setup 
Networking support (CONFIG_NET) [Y/n/?] 
PCI support (CONFIG_PCI) [Y/n/?] 
PCI access mode (BIOS, Direct, Any) [Any] 
defined CONFIG_PCI_GOANY 
PCI device name database (CONFIG_PCI_NAMES) [Y/n/?] 
System V IPC (CONFIG_SYSVIPC) [Y/n/?] 
Sysctl support (CONFIG_SYSCTL) [Y/n/?] 
Kernel core (/proc/kcore) format (ELF, A.OUT) [ELF] 
defined CONFIG_KCORE_ELF 
* Plug and Play configuration 
Plug and Play support (CONFIG_PNP) [Y/n/?] 
* Block devices 
Normal PC floppy disk support (CONFIG_BLK_DEV_FD) [Y/n/?] 
* Networking options 
Kernel/User netlink socket (CONFIG_NETLINK) [Y/n/?] 
Routing messages (CONFIG_RTNETLINK) [Y/n/?] 
Network packet filtering (replaces ipchains) (CONFIG_NETFILTER) [Y/n/?] 
Unix domain sockets (CONFIG_UNIX) [Y/n/?] 
TCP/IP networking (CONFIG_INET) [Y/n/?] 
IP: advanced router (CONFIG_IP_ADVANCED_ROUTER) [Y/n/?] 
IP: policy routing (CONFIG_IP_MULTIPLE_TABLES) [Y/n/?] 
IP: use netfilter MARK value as routing key (CONFIG_IP_ROUTE_FWMARK) [Y/n/?] 
IP: fast network address translation (CONFIG_IP_ROUTE_NAT) [Y/n/?] 
IP: equal cost multipath (CONFIG_IP_ROUTE_MULTIPATH) [Y/n/?] 
* IP: Netfilter Configuration 
Connection tracking (required for masq/NAT) (CONFIG_IP_NF_CONNTRACK) [Y/n/?] 
FTP protocol support (CONFIG_IP_NF_FTP) [Y/n/?] 
IP tables support (required for filtering/masq/NAT) (CONFIG_IP_NF_IPTABLES) [Y/n/?] 
limit match support (CONFIG_IP_NF_MATCH_LIMIT) [Y/n/?] 
Multiple port match support (CONFIG_IP_NF_MATCH_MULTIPORT) [Y/n/?] 
Connection state match support (CONFIG_IP_NF_MATCH_STATE) [Y/n/?] 
Packet filtering (CONFIG_IP_NF_FILTER) [Y/n/?] 
Full NAT (CONFIG_IP_NF_NAT) [Y/n/?] 
REDIRECT target support (CONFIG_IP_NF_TARGET_REDIRECT) [Y/n/?] 
LOG target support (CONFIG_IP_NF_TARGET_LOG) [Y/n/?] 
ATA/IDE/MFM/RLL support (CONFIG_IDE) [Y/n/?] 
* IDE, ATA and ATAPI Block devices 
Enhanced IDE/MFM/RLL disk/cdrom/tape/floppy support (CONFIG_BLK_DEV_IDE) [Y/n/?] 
Include IDE/ATA-2 DISK support (CONFIG_BLK_DEV_IDEDISK) [Y/n/?] 
Use multi-mode by default (CONFIG_IDEDISK_MULTI_MODE) [Y/n/?] 
Include IDE/ATAPI CDROM support (CONFIG_BLK_DEV_IDECD) [Y/n/?] 
* SCSI support 
SCSI support (CONFIG_SCSI) [Y/n/?] 
* SCSI support type (disk, tape, CD-ROM) 
SCSI disk support (CONFIG_BLK_DEV_SD) [Y/n/?] 
Maximum number of SCSI disks that can be loaded as modules (CONFIG_SD_EXTRA_DEVS) [8] 
* Some SCSI devices (e.g. CD jukebox) support multiple LUNs 
Enable extra checks in new queueing code (CONFIG_SCSI_DEBUG_QUEUES) [Y/n/?] 
* SCSI low-level drivers 
AMI MegaRAID support (CONFIG_SCSI_MEGARAID) [Y/n/?] 
SYM53C8XX SCSI support (CONFIG_SCSI_SYM53C8XX) [Y/n/?] 
default tagged command queue depth (CONFIG_SCSI_NCR53C8XX_DEFAULT_TAGS) [4] 
maximum number of queued commands (CONFIG_SCSI_NCR53C8XX_MAX_TAGS) [32] 
synchronous transfers frequency in MHz (CONFIG_SCSI_NCR53C8XX_SYNC) [80] 
* Network device support 
Network device support (CONFIG_NETDEVICES) [Y/n/?] 
* Ethernet (10 or 100Mbit) 
Ethernet (10 or 100Mbit) (CONFIG_NET_ETHERNET) [Y/n/?] 
EISA, VLB, PCI and on board controllers (CONFIG_NET_PCI) [Y/n/?] 
EtherExpressPro/100 support (CONFIG_EEPRO100) [Y/n/?] 
* Input core support 
Input core support (CONFIG_INPUT) [Y/n/?] 
Keyboard support (CONFIG_INPUT_KEYBDEV) [Y/n/?] 
* Character devices 
Virtual terminal (CONFIG_VT) [Y/n/?] 
Support for console on virtual terminal (CONFIG_VT_CONSOLE) [Y/n/?] 
Standard/generic (8250/16550 and compatible UARTs) serial support (CONFIG_SERIAL) [Y/n/?] 
Unix98 PTY support (CONFIG_UNIX98_PTYS) [Y/n/?] 
Maximum number of Unix98 PTYs in use (0-2048) (CONFIG_UNIX98_PTY_COUNT) [8] 
* File systems 
Reiserfs support (CONFIG_REISERFS_FS) [Y/n/?] 
ISO 9660 CDROM file system support (CONFIG_ISO9660_FS) [Y/n/?] 
/proc file system support (CONFIG_PROC_FS) [Y/n/?] 
/dev/pts file system for Unix98 PTYs (CONFIG_DEVPTS_FS) [Y/n/?] 
* Console drivers 
VGA text console (CONFIG_VGA_CONSOLE) [Y/n/?] 

这里需要说明的是：如果要使用透明代理模式，要仔细选择Netfilter，因为我们还得用iptables来重定向tcp包，以满足透明代理的要求。 
假如您的服务器配置与我的不同，只需要更改相应的硬件配置参数即可，比如CPU类型、网卡、SCSI硬盘等。 

接着： 
make bzImage 

完成后，将 arch/i386/boot/目录下的新内核bzImage拷贝到/boot/目录下，并更名为opt： 
cp arch/i386/boot/bzImage /boot/ 
mv /boot/bzImage /boot/opt 

然后编辑lilo.conf如下所示： 
boot=/dev/sda 
map=/boot/map 
install=/boot/boot.b 
prompt 
timeout=50 
message=/boot/message 
default=opt 

image=/boot/vmlinuz-2.4.2-2 
label=linux 
initrd=/boot/initrd-2.4.2-2.img 
read-only 
root=/dev/sda1 

image=/boot/opt 
label=opt 
read-only 
root=/dev/sda1 

最后执行： 
# lilo 
Added linux 
Added opt * 

好了，这样我们就可以用新内核启动了，您可以发现，这样自己编译的内核要小的多，也快得多。 
Squid优化完全手册(2) 

http://LinuxAid.com.cn 01-10-14 18:12 58p bye2000 
-------------------------------------------------------------------------------- 


三、 使用reiserfs文件系统 

有人做过测试，在相同条件下，如果cache分区使用reiserfs文件系统，性能要比使用ext2的高出20%，所以我们将在cache分区中采用reiserfs文件系统。在上一步中，我们已经在内核中提供了对reiserfs的支持，下面我们要做的，就是将原来的cache分区重新格式化成reiserfs文件系统。 

首先从ftp://ftp.namesys.com/pub/reiserfsprogs/reiserfsprogs-3.x.0j.tar.gz下载reiserfs文件系统相关工具reiserfsprogs，然后解开该文件： 
tar xvzf reiserfsprogs-3.x.0j.tar.gz 

进入新生成目录，执行： 
./configure 
make 
make install 
这将生成mkreiserfs、reiserfsck、debugreiserfs、resize_reiserfs四个reiserfs的工具。 

完成后我们将reiserfs工具安装成功了。这时，假设原来的cache分区为/dev/sda7，所装载的目录为/cache，在对其格式化之前，我们要先umount 原来的分区： 
umount /cahce 

对分区格式化，我们执行： 
mkreiserfs Ch r5 /de/sda7 

完成后我们修改/etc/fstab，将/cache一行改为： 
/dev/sda7 /cache reiserfs notail,noatime 0 0 
然后重启动。 

四、 重新编译squid 

经过大量的测试表明：squid-2.2.STABLE5＋hno补丁的组合要比2.3或者是其他版本的squid都要稳定的多、效率也要高的多，如果您不相信可以自己化几天时间做一下测试。所以我们将采用这个版本的squid。 
首先从http://www.squid-cache.org/Versions/v2/2.2/下载squid-2.2.STABLE5-src.tar.gz， 从http://prdownloads.sourceforge.net/squid/下载squid-2.2.STABLE5-hno.20000202.snapshot.gz补丁，然后分别解开这两个包： 
tar xvzf squid-2.2.STABLE5-src.tar.gz 
gunzip Cd squid-2.2.STABLE5-hno.20000202.snapshot.gz 

然后打补丁： 
cd squid-2.2.STABLE5 
patch Cp1 < ../ squid-2.2.STABLE5-hno.20000202.snapshot 

接下来，就可以开始编译squid了，在采用异步io（多线程模式）之外，我们本着这样一个原则：那就是去掉一切不需要的功能，如下所示： 
./configure --prefix=/usr --exec_prefix=/usr --bindir=/usr/sbin --libexecdir=/usr/lib/squid --localstatedir=/var --sysconfdir=/etc/squid --mandir=/usr/share/man --enable-async-io=20 --disable-icmp --disable-delay-pools --disable-mem-gen-trace --disable-useragent-log --enable-kill-parent-hack --disable-arp-acl --enable-poll --disable-ident-lookups 

make 
make install 

其中，--enable-async-io=20说明我们采用异步io，并采用18个线程。 
编译通过后，我们就可以开始配置squid了。 

五、 优化squid配置 

以下是我的squid.conf及相关解释： 

#取消对代理阵列的支持 
icp_port 0 

#对日志文件和pid文件位置进行设置 
cache_store_log none 
cache_access_log /var/log/squid/access.log 
cache_log /var/log/squid/cache.log 
emulate_httpd_log on 
pid_filename /var/run/squid.pid 

#设置运行时的用户和组权限 
cache_effective_user squid 
cache_effective_group squid 

#设置管理信息 
visible_hostname proxy.yxtc.edu.cn 
cache_mgr bye2000@yxtc.edu.cn 

#设置监听地址和端口 
http_port 3128 
tcp_incoming_address x.x.x.x 
udp_incoming_address x.x.x.x 

#见下面补充说明 
cache_mem 32 MB 
cache_dir /cache 6000 14 256 

#设置cache对象超时时间 
reference_age 3 months 

#访问控制设置 
acl mynet src 192.168.1.0/255.255.255.0 
acl all src 0.0.0.0/0.0.0.0 
http_access allow mynet 
http_access deny all 

#透明代理设置 
httpd_accel_host virtual 
httpd_accel_port 80 
httpd_accel_with_proxy on 
httpd_accel_uses_host_header on 

#swap 性能微调 
half_closed_clients off 
cache_swap_high 100% 
cache_swap_low 80% 
maximum_object_size 1024 KB 

#见补充说明 
refresh_pattern -i .html 1440 90% 129600 reload-into-ims 
refresh_pattern -i .shtml 1440 90% 129600 reload-into-ims 
refresh_pattern -i .hml 1440 90% 129600 reload-into-ims 
refresh_pattern -i .gif 1440 90% 129600 reload-into-ims 
refresh_pattern -i .swf 1440 90% 129600 reload-into-ims 
refresh_pattern -i .jpg 1440 90% 129600 reload-into-ims 
refresh_pattern -i .png 1440 90% 129600 reload-into-ims 
refresh_pattern -i .bmp 1440 90% 129600 reload-into-ims 
refresh_pattern -i .js 1440 90% 129600 reload-into-ims 

补充说明： 

1．cache_mem 32 MB 
注意：cache_mem并不是squid所能使用内存的大小，而是squid用户hot object的物理内存的大小，所以这个值可以小一些。 

2．cache_dir /cache 6000 14 256 
对于第一级子目录和第二级子目录的计算方法，可以参考笔者以前的文章《用LINUX架设代理服务器（上）（中）（下）》; 

3．refresh_pattern -i .html 1440 90% 129600 reload-into-ims等
这几句其实是强行控制对象的超时时间，这违反了http协议的精神，但是在带宽较窄的场合，可以提高明显系统相应时间。 

4．注意/cache目录及日志文件的权限，其所有用户和所有组必须为squid； 

5．可以采用rpm包的脚本/etc/rc.d/init.d/squid控制squid，也可以采用squid命令控制，具体可以参考squid Ch 

==============================
3.cache_dir Directory-Name Mbytes Level-1 Level2  
思路：硬盘为8.4G的，在安装系统时应该做好规划，为不同的文件系统划分可用空间。在本例中，我们可以这样来划分：  
/cache1 3.5G  
/cache2 3.5G  
/var 400M  
swap 127M  
/ 剩余部分  
并且，在安装时，我们尽量不安装不必要的包。这样在节约空间的同时可以提高系统的安全性和稳定性。下面我们来计算所需的第一级和第二级子目录数。  
已知量：  
DS = 可用交换空间总量（单位KB）/ 交换空间数目＝7G/2=3500000KB  
OS = 平均每个对象的大小= 20k  
NO = 平均每个二级子目录所存储的对象数目 = 256  
未知量：  
L1 = 一级子目录的数量  
L2 = 二级子目录的数量  
计算公式：  
L1 x L2 = DS / OS / NO＝3500000/20/256=684  
我们取  
L1=16  
L2=43  
所以，我们的cache_dir语句为：  
cache_dir /cache1 3500M 16 43  
cache_dir /cache2 3500M 16 43  





============================================================
学习CDN不得不读之-Squid优化补遗
上一篇 / 下一篇  2008-06-10 14:55:32 / 个人分类：Linux相关文章 

查看( 404 ) / 评论( 0 ) / 评分( 0 / 0 ) 
 很早以前就看过这个几个有关Squid优化的文章，玩了这么久,在回过来在看看，又有不同的感觉，还很深.非常不错,值的所有的玩squid的人都好好读读.

学习CDN不得不读之-Squid 高级优化指南
A. 数据反馈
康神教导我们：反馈是做一切事情的基础，优化也不例外。

那么具体看一些什么反馈数据呢？很遗憾，这个问题没有固定的答案，基本上需要具体问题具体分析。具体来说，用 cacti 之类的看 squid snmp 数据是第一步。主要的数据有：
BHR (Byte Hit Rate)/RHR (Request Hit Rate)，这两个分别表示有多少数据量/请求数是被squid hit cache 的。要特别注意的是，squid hit cache 并不等于 squid 不往主服务器发请求。具体情况在squid 2.5/2.6 里面参看 isTcpHit() 函数。举个例子，如果 RHR 显示 90%，那么可能有 20% 的请求 squid还是往主服务器发送了请求询问它过期的 cache内容是否有变化的，只不过主服务器的回应是没有变化。主服务器的判断一般需要一次数据库查询或者文件系统的 stat调用。高负荷服务器到最后如果瓶颈在主服务器磁盘 I/O，这些貌似 HIT 的请求也会对主服务器造成一定量的冲击。单纯盲目追求高BHR/RHR
是不可靠的。Service Time，这个是各类请求的回应时间，但是这个时间受到外部网络速度的影响，所以也不一定代表真实的性能。另外，如果出现Miss Service Time 比别的几个 Service Time指标高出很多，表示去主服务器的请求耗时比较长，一般是代表瓶颈在主服务器那里，但这也不是绝对的。如果 squid 服务器磁盘 I/O性能跟不上或者 CPU 不够强劲（squid 2 核心是可怜的单进程），那么也可能是 squid 本身的调度出了问题。Storage，在特定情况下可以估算 squid 每天缓存多少东西，在配置缓存大小等问题的时候会有帮助。

总的来说，squid snmp 数据是需要根据具体情况分析的，而且 squid snmp的数据也不多，有时候往往需要配合别的监控来综合分析问题，比方网络出入流量，服务器的各类性能分析，主服务器和 squid access log。有一次我在某站 squid 调整了一个参数，结果那天 squid 的反应奇好，BHR 更是上了前所未有的98%。但是后来反复推敲发现这个参数并没有作用，结合各类 log 分析发现是因为那天 frjj 贴了新照片，而且被盗链，导致巨大比例的frjj 照片的请求被 squid 有效的缓存，squid 网络出流量激增也支持这个结论。说了半天，中心意思是高负荷服务器的 squid优化是一个长期而艰巨的任务，某些参数的优化需要几天的数据才能得出有意义的结论，所以需要有足够的耐心和针对实际情况的系统化的优化步骤。

 

B. 缓存策略
康神教导我们：一般来说，（缓存策略）如果后端不是配置很麻烦，建议还是在后端做，前端的配置修改大多数都是违背 http 协议的，如果出现问题，也比较难排查。

HTTP 缓存协议比较权威的可以参考 RFC 2616 第十三章，特别是 13.2 和 13.3 节。具体实现可以参考比方 Firefox 代码 nsHttpResponseHead.cpp的 ComputeCurrentAge() 和 ComputeFreshnessLifetime()函数看看各类情况的处理方式。mod_expires的配置就需要深刻理解这些基本概念，否则可能反而会增加请求数。如果没有特别的理由，静态文件的过期时间一般是设置为 access time加上一定量的时间。这个一定量的时间由具体情况决定。比如网站建设初期，各类静态文件可能需要比较短的过期时间以方便网站更新；而一旦美工敲定图片，图片的过期时间可以大胆的设置为几个月。在配置完成以后如果没有很大的把握也可以实际浏览一下分析请求序列看是否浏览器端和 squid服务器都做到了有效的缓存，特别注意 cache 相关的请求和回复头，包括 squid 提供的 X-Cache 头。
另外，虽然违反 HTTP 协议的 squid 配置一般都不推荐，但是具体到细节上，这也不是绝对的原则。下面举例说说必须违反 HTTP 协议的情况。
使用 javascript做镜像网站测速，一般实现方式是从各个镜像站下载一个图片看哪一个最快。最理想的情况是图片在浏览器端不要缓存（以便下次准确测速），但是这个请求又完全没必要打到主服务器上。那么可以在 squid 里针对这个图片 url 配置强制缓存 refresh_pattern reload-into-ims ignore-reload。当然这个例子很土鳖，只是举个例子。reload_into_ims （这里说的是 squid 的配置参数，不是 refresh_pattern 里面的 option）。这个参数虽然违反 HTTP 协议但是对大部分网站来说是可以设置为 on 的，只要后端服务器对 If-Modified-Since 头的判断正确并且没有潜在安全问题即可。浏览器 F5 刷新和 javascript. 的 location.reload() 刷新可能会重新请求所有的网页内嵌元素并且可能带 no-cache 请求头，一般来说 reload_into_ims 设置成 on 已经足够保证对主服务器不造成冲击，但是如果有必要可能还是需要在 squid 配置强制缓存。针对土鳖客户端的优化。比如早期的 fterm 预览图片会发送 Pragma: no-cache 的请求头，这势必导致所有 fterm 预览图片的请求如数全部打在后端服务器上，所以解决方法是 squid 这里做手脚针对这类 url 配置强制缓存。一个细节问题是如果不能缓存的图片（比方有察看权限限制的）和能缓存的图片的 url 结构完全一样，那么在 squid 强制缓存这类 url 的话又会有潜在的安全问题，这里涉及到后面会讲到的网站结构优化，针对这个问题需要修改网站的代码以明确区分这两类 url。还有另外一个例子是早期的 firefox 发送 XMLHttpRequest 请求也会发送 no-cache 的头，后来的版本改了。当年这一类 ajax 请求的 url 也是需要配置强制缓存的。最后一个问题是，如果在特殊情况下必须在后端服务器发送 Expires 头，并且同时又在 squid 中配置这类 url 的 refresh_pattern，那么需要特别小心。比如，如果 squid 强制缓存时间比 mod_expires配置的过期时间长，那么可能造成 squid 发送已经过期的内容，导致浏览器本来可以有效缓存的内容却需要不断的向服务器检查更新。

最后，有些后端服务器没办法配置 mod_expires。这可能是因为没有配置权限，也可能是因为后端服务器软件太土鳖，总之这样的情况下就必须用 squid 配置 refresh_pattern 了。


C. 网站代码及结构优化
康神教导我们：很多 squid 优化（的文章）只限于在 squid 参数和系统参数上面的调整。但是这个实在只是细枝末节的事情，只要不是太弱智的配置导致无法缓存，squid 的性能不会有太大差距。
网站优化一般来说也是属于这种类型的优化，对于主服务器负荷瓶颈在磁盘 I/O，或者网络瓶颈是大量大图片文件的情况，优化网站 html结构可能对性能提升没有半点作用。不过即便如此，有一个为 squid 考虑的网站结构，可以使得 squid服务器的配置比较容易，也可以比较容易的实现多 squid业务分拆，有的时候业务分拆并不是为了性能，而是为了更好的分析问题以便进一步优化网站。下面简要说说有可能提高性能的网站代码优化。
减少页面大小。这个问题实在是到处都有好文章，我就不详细说了。常见技巧是分离 css/js到单独文件减少动态主页面大小同时保证静态内容有效缓存；页面 layout 设计尽量使用 div+css；有大量冗余 html 元素的部分使用javascript. 来输出。最后这个页面 javascript. 化可能需要考虑搜索引擎优化 (SEO) 的问题，总的来说需要在减少流量和SEO 之间寻找一个好的平衡点，这个只有做网站的人自己最清楚。减少同一份数据的不同表现形式。大量使用 ajax 的站点有时候考虑 SEO 往往要重写一套给搜索引擎看的页面，这势必导致 squid这里要存两套页面。但是如果功力足够还是可以做到大部分页面重用。举例来说，网站可能希望用户读文章不切换页面而使用 XMLHttpRequest载入，这个就可以在 <a href 写上文章内容的页面以便搜索引擎扒站同时也允许用户在新窗口打开这个文章，而 onclick 事件则触发XMLHttpRequest 载入页面并分析显示内容。只要代码写的足够漂亮，这里用一个文章页面就可以实现所有的功能。标准化 url。这个可以算前一条的补充。写网站如果不小心，可能同一个资源会有不同的 url。比方某篇文章，从主页进去的 url 是
article?bid=3&id=50，从搜索结果进去却是
article?id=50&bid=3。这样两个页面，不但影响外部搜索引擎排名（自己和自己打架），更会影响 squid 效率，因为squid 需要单独存这两类页面。网站建设初期充分考虑到将来的 squid 优化。举例来说，很多网站都在页面带用户登录信息显示，这样的页面如果不使用javascript. 技巧就完全不可以在 squid 这里 cache。而实际上，如果这些动态内容可以在 javascript. 里面通过cookie 判断出来，那么完全可以用 javascript. 来写。这方面的细节工作做得越好，就有越多的页面可以被 squid安全的缓存。当然这方面的优化有时候也只有网站运行起来才能发现，维护网站的时候多分析log，多观察，就可以发现这些细小的可以优化的地方，水滴石穿，大量小细节的优化也可以带来可观的性能提升。

D. 一些杂问题
同步 squid 和主服务器的时钟。从原理上说即使主服务器、squid以及浏览器端的时钟都不同步，应该也不会造成缓存策略上的问题，但是为了防止诡异问题的发生，还是配置一下 squid 和主服务器的 ntpd为好。ntp 是一个极轻量级的协议，现在网络上 ntpd server 也遍地都是，保证服务器时钟准确到 1秒之内也可以保证别的一些程序的事务处理逻辑。密切注意搜索引擎的动向。有一些搜索引擎做的比较弱智，有的时候会突然发很多请求过来。搜索引擎扒站很容易扒到冷僻内容，所以即使请求量只是普通浏览用户请求量的零头，也可能会对主服务器造成冲击。大部分搜索引擎还是比较守规矩的，甚至有些搜索引擎公司还可以与他们接触配置扒站方案。不老实的搜索引擎可以通过 squid 或者主服务器 log 找出来，特别不老实的可能 iptables 都能发现。解决方法比如可以针对搜索引擎 user agent 判断，或者干脆 iptables 咔嚓掉。Cache replacement policy，对大论坛站点，虽然 lru 算法占用 cpu 较低，但是 service time可能会不如带 dynamic aging 的算法稳定。据观察，lru 算法在运行几天之后的早晨如果突然碰到大量新请求，新请求会很难进入cache，或者进入了也很快被踢出，导致非常容易形成恶性正反馈拖垮后台服务器。但是假如每天清晨清 cache，并且保证磁盘 cache的量稍大于每天能存下来的量，那么 lru算法应该也不会比别的算法差（事实上什么算法都一样了）。当然这只是我的一家之言，一般来说这个问题还是需要根据 squid服务器性能和网站具体情况多次反复试验选择最合适的算法。一般来说小规模和超大规模的站点优化这个参数可能不会有什么显著的性能提升，所以不建议耗费太多时间优化这个。一定时间清理 cache 并重启 squid。这个有可能只是 squid 2.5并且是高负荷破机器上需要考虑的一个方案。某站曾经有段时间每天高峰期 Miss Service Time都会飙升，但是主服务器却没有超负荷的现象，最后推测可能是 squid 自己调度的问题。后来每三天清理 cache 并重启 squid
似乎大大减少了这种现象。后据权威人士批复，这个可能是因为 squid cache replacement算法过于古老，不适应高速更新的大型论坛所致。多域名宣传的服务器。如果网站允许有多个域名但是所有的域名都指向同一个网站，那么要注意 squid
不要配置成多域名模式，否则它会把每个域名的 cache 都分开处理，导致效率低下而且不能有效利用缓存存储空间。题外话，单个网站宣传多个域名也会影响搜索引擎排名等等，所以本质上也是不推荐这么做的。maximum_object_size_in_memory，maximum_object_size
这两个参数的配置也是具体问题具体分析的。具体到某站上，常见的大文件就是附件了，由于附件最大允许大小是 5120 KB，所以maximum_object_size 配置了 5123 KB 以保证即使最大的附件加上各 HTTP 头也能有效的被缓存。最早这个参数是配置成5120 KB 的，然后曾经有一次发生 BHR 骤降的情况，后来分析发现是有人贴了 5120 KB RAR分卷压缩的李宇春同学的视频 ，而且恰好又有无数玉米下载，大量这类请求因为超容所以都压到了主服务器上。另外maximum_object_size_in_memory 的配置需要考虑网站具体情况和 squid 服务器的性能，这也需要实际试验出来。

最后废话一句，现在硬件降价很快，给机群升级扩容提升硬件性能往往比找个猪头优化 squid 配置更有效果，而且见效也快。所以在 squid 大配置没有问题的前提下，有钱的话应该首选硬件优化方案而不是软件细节优化。

